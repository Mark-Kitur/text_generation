{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75a04733",
   "metadata": {},
   "outputs": [],
   "source": [
    "config ={\n",
    "    'epochs': 50,\n",
    "    'batch_size':32,\n",
    "    'lr':0.001,\n",
    "    'd_model':512,\n",
    "    'num_heads':8,\n",
    "    'd_ff': 2048,\n",
    "    'num_layers':6,\n",
    "    'vocab_size': 5000,\n",
    "    'checkpoint_path':\"model.pth\",\n",
    "    'dropout':0.01,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33340a6",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2505618a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "def tokenize(text,vocab):\n",
    "    words = re.findall(r'\\b\\w+\\b',text)\n",
    "    words.append(\"<EOS>\")\n",
    "    words.insert(0,\"<SOS>\")\n",
    "    return [vocab.get(word,vocab[\"UNK\"]) for word in words]\n",
    "\n",
    "def detokenize(tokens,vocab):\n",
    "    #tokens= tokens.tolist()\n",
    "    reverse_vocab = {v:k for k,v in vocab.items()}\n",
    "    return \" \".join([reverse_vocab.get(token,\"UNK\") for token in tokens])\n",
    "\n",
    "def build_vocab(text, vocab_size=50000):\n",
    "    words = re.findall(r'\\b\\w+\\b',text)\n",
    "    word_counts =Counter(words)\n",
    "    most_common = word_counts.most_common(vocab_size-2)\n",
    "\n",
    "    vocab ={\"<PAD>\":0, \"UNK\":1,\"<SOS>\":2,\"<EOS>\":3}\n",
    "    vocab.update({word: idx +4 for idx,(word,_) in enumerate(most_common)})\n",
    "\n",
    "    return vocab\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a85dc5",
   "metadata": {},
   "source": [
    "# Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "066c4352",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def preprocess_text(input_file, output_file, vocab_size:int=5000, seq_len:int=64,encoding:str='utf-8'):\n",
    "    try:\n",
    "        with open(input_file, 'r', encoding=encoding) as file:\n",
    "            text= file.read().lower()\n",
    "    except UnicodeDecodeError:\n",
    "        with open(input_file, 'r', encoding='latin-1') as file:\n",
    "            text =file.read().lower()\n",
    "    except Exception as e:\n",
    "        print(f'Error reading file: {e}')\n",
    "    \n",
    "    vocab = build_vocab(text,vocab_size)\n",
    "    tokenize_text = tokenize(text,vocab)\n",
    "\n",
    "    data = [tokenize_text[i:i+seq_len] for i in range(0,len(tokenize_text)-seq_len,seq_len)]\n",
    "\n",
    "    os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "\n",
    "    torch.save((data, vocab), output_file)\n",
    "    print(f'Data saved to {output_file}')\n",
    "    print(f'Vocabulary size: {len(vocab)}')\n",
    "    print(f'Total token:{len(tokenize_text)}')\n",
    "    print(f'Number of seq:{len(data)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f9e036",
   "metadata": {},
   "source": [
    "# Downloading datset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b566a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "splits = {'train': 'data/train-00000-of-00001-679af0bccbb2f644.parquet', 'validation': 'data/validation-00000-of-00001-089cf71e86c88e28.parquet', 'test': 'data/test-00000-of-00001-ae1348a38be3cb29.parquet'}\n",
    "df = pd.read_parquet(\"hf://datasets/Sandipan1994/Inference_Text_Generation/\" + splits[\"train\"])\n",
    "df.drop(columns=['step'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4c098ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = pd.read_parquet(\"hf://datasets/Sandipan1994/Inference_Text_Generation/\" + splits[\"validation\"])\n",
    "df_text = pd.read_parquet(\"hf://datasets/Sandipan1994/Inference_Text_Generation/\" + splits[\"test\"])\n",
    "df_d = pd.concat([df,df_val],ignore_index=True)\n",
    "df_d.drop(columns=['step'],inplace=True)\n",
    "df_val.drop(columns=['step'],inplace=True)\n",
    "df_text.drop(columns=['step'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7c94250d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to E:/data sciences/LLMs/gen/text_generation/data_train.csv\n",
      "Saved to E:/data sciences/LLMs/gen/text_generation/data_val.csv\n",
      "Saved to E:/data sciences/LLMs/gen/text_generation/data_test.csv\n"
     ]
    }
   ],
   "source": [
    "path_train ='E:/data sciences/LLMs/gen/text_generation/data_train.csv'\n",
    "path_val ='E:/data sciences/LLMs/gen/text_generation/data_val.csv'\n",
    "path_test ='E:/data sciences/LLMs/gen/text_generation/data_test.csv'\n",
    "\n",
    "df.to_csv(path_train,index=False)\n",
    "df_val.to_csv(path_val,index=False)\n",
    "df_text.to_csv(path_test,index=False)\n",
    "print(f'Saved to {path_train}')\n",
    "print(f\"Saved to {path_val}\")\n",
    "print(f\"Saved to {path_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1aa88db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([df,df_val,df_text],ignore_index=True)\n",
    "data.to_csv('E:/data sciences/LLMs/gen/text_generation/data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d65750a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "inference",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "14c06dda-9394-4a5d-88b2-3ff418a792d0",
       "rows": [
        [
         "0",
         "leo is a constellation containing stars"
        ],
        [
         "1",
         "the earth revolving around the sun causes leo to appear in different areas in the sky at different times of year"
        ],
        [
         "2",
         "apparent motion of stars is when stars appear to move relative to earth's position"
        ],
        [
         "3",
         "the earth rotating on its axis causes apparent motion of stars"
        ],
        [
         "4",
         "the earth rotating on its axis causes stars to move relative to the horizon during the night"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>leo is a constellation containing stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the earth revolving around the sun causes leo ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>apparent motion of stars is when stars appear ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the earth rotating on its axis causes apparent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the earth rotating on its axis causes stars to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           inference\n",
       "0            leo is a constellation containing stars\n",
       "1  the earth revolving around the sun causes leo ...\n",
       "2  apparent motion of stars is when stars appear ...\n",
       "3  the earth rotating on its axis causes apparent...\n",
       "4  the earth rotating on its axis causes stars to..."
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(path_train)\n",
    "df.iloc[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26579423",
   "metadata": {},
   "source": [
    "# convert CSV to .txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "031cb7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "text_train='E:/data sciences/LLMs/gen/text_generation/data_train.txt'\n",
    "text_val='E:/data sciences/LLMs/gen/text_generation/data_val.txt'\n",
    "text_test='E:/data sciences/LLMs/gen/text_generation/data_test.txt'\n",
    "text_data='E:/data sciences/LLMs/gen/text_generation/data.txt'\n",
    "\n",
    "with open(text_train,\"w\") as output_file:\n",
    "    with open(path_train,\"r\") as input_file:\n",
    "        [output_file.write(\" \".join(row)+'\\n') for row in csv.reader(input_file)]\n",
    "        \n",
    "with open(text_val,\"w\") as output_file:\n",
    "    with open(path_val,\"r\") as input_file:\n",
    "        [output_file.write(\" \".join(row)+'\\n') for row in csv.reader(input_file)]\n",
    "\n",
    "with open(text_test,\"w\") as output_file:\n",
    "    with open(path_test,\"r\") as input_file:\n",
    "        [output_file.write(\" \".join(row)+'\\n') for row in csv.reader(input_file)]\n",
    "\n",
    "with open(text_data,\"w\") as output_file:\n",
    "    with open('E:/data sciences/LLMs/gen/text_generation/data.csv',\"r\") as input_file:\n",
    "        [output_file.write(\" \".join(row)+'\\n') for row in csv.reader(input_file)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9d8d6681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to E:/data sciences/LLMs/gen/text_generation/token.pt\n",
      "Vocabulary size: 3465\n",
      "Total token:65812\n",
      "Number of seq:1028\n"
     ]
    }
   ],
   "source": [
    "data_tokens ='E:/data sciences/LLMs/gen/text_generation/token.pt'\n",
    "input_text= \"E:/data sciences/LLMs/gen/text_generation/data.txt\"\n",
    "preprocess_text(input_text,data_tokens)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e870589",
   "metadata": {},
   "source": [
    "# Building a data pipeline for feeding data in batches to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2f85ae19",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_tokens,'rb') as file:\n",
    "    data, vocab = torch.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fa526301",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomTextDataset(Dataset):\n",
    "    def __init__(self,text_data,tokenizer,voc, max_len):\n",
    "        self.text_data = text_data \n",
    "        self.tokenizer= tokenizer\n",
    "        self.voc= voc\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text_data) # number of samples in the dataset\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        data= self.text_data[index]\n",
    "\n",
    "        # tokenizer the text data\n",
    "        data_token = self.tokenizer(data, self.voc)\n",
    "\n",
    "        # truncate if too long\n",
    "        if len(data_token) >self.max_len:\n",
    "            tokens = tokens[:self.max_len]\n",
    "        else:\n",
    "            tokens= data_token\n",
    "        \n",
    "        # create input tensor (padded)\n",
    "        input_ids = torch.zeros(self.max_len,dtype=torch.long)\n",
    "        input_ids[:len(tokens)] = torch.tensor(tokens, dtype=torch.long)\n",
    "\n",
    "        # create target_ids = inputs_ids shifted left twice plus for <SOS>\n",
    "        target_ids = torch.zeros(self.max_len, dtype=torch.long)\n",
    "        if len(tokens)>1:\n",
    "            target_ids[:len(tokens)-2] =torch.tensor(tokens[2:], dtype=torch.long) \n",
    "\n",
    "        return input_ids, target_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6994402a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input ids:  tensor([   2, 2022,    7,    5, 2565,    3])\n",
      "output ids:  tensor([   7,    5, 2565,    3,    0,    0])\n"
     ]
    }
   ],
   "source": [
    "text_data= [\n",
    "    \"leo is a constellation\",\n",
    "    \"earth rotates on its axis\"\n",
    "]\n",
    "see = CustomTextDataset(text_data, tokenize, vocab, max_len=6)\n",
    "inp, tgt = see[0]\n",
    "print(\"input ids: \", inp)\n",
    "print(\"output ids: \", tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e9a109b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detokenize(tokens,vocab):\n",
    "    tokens= tokens.tolist()\n",
    "    reverse_vocab = {v:k for k,v in vocab.items()}\n",
    "    return \" \".join([reverse_vocab.get(token,\"UNK\") for token in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "44c49d42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<SOS> leo is a constellation <EOS>'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detokenize(inp,vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "afd91630",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data loader\n",
    "def file_read(path):\n",
    "    with open(path,\"r\") as f:\n",
    "        file_ =f.read().lower().split(\"\\n\")\n",
    "    return file_ \n",
    "    \n",
    "train_data = file_read(text_train)\n",
    "val_data = file_read(text_val)\n",
    "test_data =file_read(text_test)\n",
    "train_dataset =CustomTextDataset(train_data,tokenize,vocab,max_len=80)\n",
    "val_dataset =CustomTextDataset(val_data,tokenize,vocab,max_len=80)\n",
    "test_dataset =CustomTextDataset(test_data,tokenize,vocab,max_len=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e887c9cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<SOS> apparent motion of stars is when stars appear to move relative to earth s position <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_data = file_read(text_train)\n",
    "detokenize(train_dataset[3][0],vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "abfedc30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data: \n",
      " <SOS> an example of an adaptation is something that is used for getting oxygen <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "tensor([   2,   11,   47,    6,   11,  249,    7,   27,   12,    7,   24,   21,\n",
      "        1094,   52,    3,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0])\n",
      "output token: \n",
      " example of an adaptation is something that is used for getting oxygen <EOS> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "tensor([  47,    6,   11,  249,    7,   27,   12,    7,   24,   21, 1094,   52,\n",
      "           3,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset,batch_size=32,shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset,batch_size=32,shuffle=False)\n",
    "\n",
    "for batch in train_dataloader:\n",
    "    input_data_t,tgt_tokens_= batch\n",
    "\n",
    "    input_data= detokenize(input_data_t[0],vocab)\n",
    "    tgt_tokens =detokenize(tgt_tokens_[0],vocab)\n",
    "\n",
    "    print(f\"Input data: \\n\", input_data)\n",
    "    print(input_data_t[0])\n",
    "    print(f\"output token: \\n\", tgt_tokens)\n",
    "    print(tgt_tokens_[0])\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b78aaeab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa244500",
   "metadata": {},
   "source": [
    "# Model Architacture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e41c8b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self,d_model, num_heads):\n",
    "        super(MultiHeadAttention,self).__init__()\n",
    "        assert d_model % num_heads ==0, \"d_model must be divisible by num_heads\"\n",
    "\n",
    "        # initialize dimensions\n",
    "        self.d_model = d_model\n",
    "        self.num_heads= num_heads\n",
    "        self.d_k = d_model // num_heads\n",
    "\n",
    "        # linear layers for transforming the inputs queries, keys and valuea\n",
    "        self.W_q = nn.Linear(d_model,d_model)\n",
    "        self.W_k = nn.Linear(d_model,d_model)\n",
    "        self.W_v = nn.Linear(d_model,d_model)\n",
    "        self.W_o = nn.Linear(d_model,d_model)\n",
    "\n",
    "    def scaled_dot_product_aatention(self,q,k,v,mask=None):\n",
    "        attn_scores =torch.matmul(q,k.transpose(-2,-1))/ math.sqrt(self.d_k)\n",
    "\n",
    "        if mask is not None:\n",
    "            attn_scores =attn_scores.masked_fill(mask==0,float('-inf'))\n",
    "        attn_probs = torch.softmax(attn_scores,dim=-1)\n",
    "\n",
    "        output = torch.matmul(attn_scores,v)\n",
    "        return output\n",
    "    def split_head(self,x):\n",
    "        # reshape the input tensor to (batch_size, seq_len, num_heads, d_k)\n",
    "        batch_size, seq_len, d_model =x.size()\n",
    "        return x.view(batch_size,seq_len, self.num_heads,self.d_k).transpose(1,2)\n",
    "    \n",
    "    def combine_heads(self,x):\n",
    "        batch_size, num_heads, seq_len, d_k =x.size()\n",
    "        return x.transpose(1,2).contiguous().view()(batch_size,seq_len,self.d_model)\n",
    "    \n",
    "    def forward(self,q,k,v,mask=None):\n",
    "        # linear transformation and split\n",
    "        Q= self.split_head(self.W_q(q))\n",
    "        K = self.split_head(self.W_k(k))\n",
    "        V = self.split_head(self.W_v(v))\n",
    "\n",
    "        attn_output = self.scaled_dot_product_aatention(Q,K,V,mask)\n",
    "        attn_output =self.W_o(self.combine_heads(attn_output))\n",
    "\n",
    "        return attn_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0620aa74",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionWiseFeedForward(nn.Module):\n",
    "    def __init__(self,d_model,d_ff,dropout=0.1):\n",
    "        super(PositionWiseFeedForward,self).__init__()\n",
    "        self.fc1 = nn.Linear(d_model,d_ff)\n",
    "        self.fc2 = nn.Linear(d_ff,d_model)\n",
    "        self.activation =nn.GeLU()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.dropout(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8978d206",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self,d_model,max_seq_len):\n",
    "        super(PositionalEncoding,self).__init__()\n",
    "\n",
    "        pe = torch.zeros(max_seq_len,d_model)\n",
    "        position =torch.arange(0, max_seq_len,dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0,d_model,2).float()* - (math.log(10000.0)/d_model))\n",
    "\n",
    "        pe[:,0::2] = torch.sin(position*div_term)\n",
    "        pe[:,1::2] = torch.cos(position*div_term)\n",
    "\n",
    "        self.register_buffer('pe',pe.unsqueeze(0))\n",
    "\n",
    "    def forward(self,x):\n",
    "        return x + self.pe[:, :x.size(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414516de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self,d_model, num_heads,d_ff,dropout):\n",
    "        super(DecoderLayer,self).__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.feed_forward = PositionWiseFeedForward(d_model, d_ff, dropout)\n",
    "        self.norm1 =nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self,x,mask):\n",
    "        attn_output = self.self_attn(x,x,x,mask)\n",
    "        x =self.norm1(x + self.dropout(attn_output))\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm2(x+self.dropout(ff_output))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e933b5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self,vocab_size, d_model, num_heads, num_layers, d_ff,max_seq_len, dropout,device):\n",
    "        super(Transformer,self).__init__()\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.device = device\n",
    "        self.decoder_embedding = nn.Embedding(vocab_size,d_model)\n",
    "        self.positional_encoding= PositionalEncoding(d_model, max_seq_len)\n",
    "\n",
    "        self.decoder_layers = nn.ModuleList([DecoderLayer(d_model,num_heads,d_ff,dropout) for _ in range(num_layers)])\n",
    "\n",
    "        self.fc= nn.Linear(d_model,vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def genarate_mask (self,data):\n",
    "        # padding mask\n",
    "        pad_mask = (data !=0).unsqueeze(1).unsqueeze(2)\n",
    "\n",
    "        # casual mask (seq_len, seq_len)\n",
    "        seq_len = data.size(1)\n",
    "        casual_mask = torch.tril(torch.ones((seq_len,seq_len),device=self.device)).unsqueeze(0).unsqueeze(1)\n",
    "\n",
    "        # combine all only non-pad + past tokens\n",
    "        mask = pad_mask & casual_mask\n",
    "        return mask\n",
    "    \n",
    "    def forward(self, data):\n",
    "        mask =self.genarate_mask(data)\n",
    "\n",
    "        data_embed = self.dropout(self.positional_encoding(self.decoder_embedding(data)))\n",
    "        x = data_embed\n",
    "        for layer in self.decoder_layers:\n",
    "            x = layer(x,mask)\n",
    "        output = self.fc(x)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bd8046",
   "metadata": {},
   "source": [
    "# Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2ff2f4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer(config['vocab_size'],\n",
    "                    config['d_model'],\n",
    "                    config['num_heads'],\n",
    "                    config['num_layers'],\n",
    "                    config['d_ff'],\n",
    "                    config['vocab_size'],\n",
    "                    config['dropout'],\n",
    "                    device=device\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c49b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "def train_model(vocab_size, config, device):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config['lr'])\n",
    "    criterion = torch.nn.CrossEntropyLoss(ignore_index=0)  # ignore padding\n",
    "\n",
    "    # Create checkpoint folder\n",
    "    os.makedirs(os.path.dirname(config['checkpoint_path']), exist_ok=True)\n",
    "\n",
    "    for epoch in range(config['epochs']):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        for input_seq, target_seq in train_dataloader:\n",
    "            input_seq = input_seq.to(device)\n",
    "            target_seq = target_seq.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(input_seq)  # (batch, seq_len, vocab_size)\n",
    "\n",
    "            # Flatten for CE Loss\n",
    "            loss = criterion(\n",
    "                logits.view(-1, vocab_size),\n",
    "                target_seq.view(-1)\n",
    "            )\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item() * input_seq.size(0)\n",
    "\n",
    "        avg_loss = total_loss / len(train_dataloader.dataset)\n",
    "        print(f\"Epoch {epoch+1}/{config['epochs']}, Avg Loss: {avg_loss:.4f}\")\n",
    "\n",
    "        # Save checkpoint\n",
    "        torch.save(model.state_dict(), config['checkpoint_path'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
